# LLM Configuration (Default fallback for all tasks)
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7

# Task-Specific LLM Configuration (Optional - falls back to OPENAI_* if not set)
# Use different models for different tasks to optimize cost/quality

# Crawler LLM - for HTML parsing and pattern discovery (can use cheaper/faster model)
# CRAWLER_LLM_API_KEY=sk-your-api-key-here
# CRAWLER_LLM_BASE_URL=https://api.openai.com/v1
# CRAWLER_LLM_MODEL=gpt-4o-mini
# CRAWLER_LLM_MAX_TOKENS=500
# CRAWLER_LLM_TEMPERATURE=0.1

# Glossary LLM - for term extraction from sample chapters
# GLOSSARY_LLM_API_KEY=sk-your-api-key-here
# GLOSSARY_LLM_BASE_URL=https://api.openai.com/v1
# GLOSSARY_LLM_MODEL=gpt-4o
# GLOSSARY_LLM_MAX_TOKENS=4096
# GLOSSARY_LLM_TEMPERATURE=0.3

# Translator LLM - for main translation task (use best quality model)
# TRANSLATOR_LLM_API_KEY=sk-your-api-key-here
# TRANSLATOR_LLM_BASE_URL=https://api.openai.com/v1
# TRANSLATOR_LLM_MODEL=gpt-4o
# TRANSLATOR_LLM_MAX_TOKENS=4096
# TRANSLATOR_LLM_TEMPERATURE=0.7

# Crawler Configuration
CRAWLER_DELAY_MS=1000
CRAWLER_MAX_RETRIES=3
CRAWLER_TIMEOUT_SECONDS=30
CRAWLER_USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36

# Translation Configuration
TRANSLATION_CHUNK_SIZE=2000
TRANSLATION_CHUNK_OVERLAP=300
TRANSLATION_PROGRESSIVE_GLOSSARY=true

# Glossary Generation Configuration
TRANSLATION_GLOSSARY_SAMPLE_CHAPTERS=5
TRANSLATION_GLOSSARY_SAMPLE_SIZE=3000
TRANSLATION_GLOSSARY_MIN_ENTRIES=20
TRANSLATION_GLOSSARY_MAX_ENTRIES=100
TRANSLATION_GLOSSARY_RANDOM_SAMPLE=true

# Calibre Configuration
CALIBRE_PATH=ebook-convert

# Export Configuration
EXPORT_PARALLEL_WORKERS=8
EXPORT_VOLUME_SIZE=0
EXPORT_FAST_MODE=true

# Logging
LOG_LEVEL=INFO

# Streaming Pipeline Configuration
PIPELINE_TRANSLATOR_WORKERS=3
PIPELINE_QUEUE_SIZE=10
PIPELINE_CRAWL_DELAY_MS=1000
